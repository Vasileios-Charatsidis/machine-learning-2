\documentclass[a4paper,landscape]{amsmlaj}
\usepackage{anysize}
\usepackage[fontsize=9pt]{scrextend}
\usepackage{multicol}

\author{Andrea Jemmett}
\title{Machine Learning 2 - Cheat Sheet}
\date{\today}

\pagenumbering{gobble}
\marginsize{.2in}{.2in}{-.2in}{-.2in}

% Turn off header and footer
\pagestyle{empty}

\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}

\makeatletter
% Redefine maketitle
\def\maketitle{
	\textbf{\@title} \\
	\@author\quad-\quad\small{\@date}
}
% Redefine sections
\renewcommand{\section}{\@startsection{section}{1}{0mm}
	{-0ex plus -.1ex minus -.5ex}
	{0.1ex plus .7ex}
	{\normalfont\normalsize\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}
	{-1ex plus -.5ex minus -.2ex}
	{0.1ex plus .2ex}
	{\normalfont\footnotesize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}
	{-1ex plus -.5ex minus -.2ex}
	{0.1ex plus .2ex}
	{\normalfont\scriptsize\bfseries}}
\makeatother

\begin{document}
\maketitle
\begin{multicols*}{3}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\section{Probability Theory}
\subsection{Independence}
$p(X,Y)=p(X)p(Y) \Leftrightarrow p(X|Y)=p(X) \Leftrightarrow p(Y|X)=p(Y)$
\subsection{Conditional Independence}
$X \ci Y \mid Z \Longleftrightarrow p(X,Y|Z)=p(X|Z)p(Y|Z)$
\subsection{Sum and Product Rules}
$p(X,Y)=p(X)p(Y|X)$, \qquad $p(X,Y,Z)=p(X)p(Y|X)p(Z|X,Y)$ \\
$p(X)=\sum_Y p(X,Y)$
\subsection{Bayes' Theorem}
$p(Y|X)=\frac{p(X|Y)p(Y)}{p(X)}$, \qquad
$p(Y|X,Z)=\frac{p(X|Y,Z)p(Y|Z)}{p(X|Z)}$

\section{Distributions}
\begin{tabular}{l|lll}
	\textbf{Binary} & Bernoulli & Binomial & Beta\\
	\textbf{Discrete} & Categorical & Multinomial & Dirichlet
\end{tabular}

\subsection{Bernoulli Distribution}
$\mathrm{Ber}(x|n) = \mu^x(1-\mu)^{1-x}$, \qquad
$\Ex[x]=\mu$, \qquad
$\Var[x] = \mu -\mu^2$, \\
$P(D,\mu) = \prod_{n=1}^N \mu^{x_n}(1 - \mu)^{1-x_n}$, \qquad
$\mu_\text{ML} = \frac{1}{N} \sum_{n=1}^N x_n$

\subsection{Binomial Distribution}
$\mathrm{Bin}(m|N,\mu) = \binom{N}{m} \mu^m(1-\mu)^{N-m}$, \qquad
$\frac{n!}{k!(n-k)!} = \binom{n}{k}$, \\
$\Ex[m] = N\mu$, \qquad
$\Var[m] = N\mu(1-\mu)$, \qquad
$\mu_\text{ML} = \frac{m}{N}$

\subsection{Categorical Distribution}
$p(\vt{x}|\vt{\mu}) = \prod_{k} \mu_k^{x_k}$, \qquad
$\vt{\mu} \in \{0,1\}^K$, \qquad
$\sum_k \mu_k = 1$, \qquad
$\vt{\mu}_\text{ML} = \frac{\vt{m}}{N}$, \\
$m_k = \sum_n x_{nk}$, \qquad
$\mathrm{Mult}(m_1 \ldots, m_k|N, \vt{\mu}) = (\frac{N!}{m_1!,\ldots,m_k} \prod_{k}) \mu_k^{mk}$
\subsection{Beta Distribution}
$\mathrm{Beta}(\mu|a,b) = \frac{\Gamma(a + b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}$,
\footnote{
	$\Gamma(x) = \int_0^1 u^{x-1}e^{-u} = 1$, \qquad
	$\Gamma(x+1) = \Gamma(x)x$, \qquad
	$\Gamma(x+1) = x!$
}\qquad
$\Ex[\mu] = \frac{a}{a + b}$, \\
$\Var[x] = \frac{ab}{(a+b)^2(a+b+1)}$, \qquad
$p(\mu|m,l,a,b) \propto \mu^{m+a-1}(1-\mu)^{l+b-1}$

\subsection{Gamma Distribution}
$\mathrm{Gamma}(\tau | a,b) = \frac{b^a}{\Gamma(a)}\tau^{a-1}e^{-b\tau}$, \qquad
$\Ex[\tau] = \frac{a}{b}$, \qquad
$\Var[\tau] = \frac{a}{b^2}$, \\
$\mathrm{mode}[\tau] = \frac{a-1}{b}$ for $a \ge 1$, \qquad
$\Ex[\ln \tau] = \psi(a) - \ln b$, \\
$H(\tau) = ln \Gamma(a) - (a-1)\psi(a) - \ln b + a$

\subsection{Multinomial Distribution}
$\vt{x} = [0,0,0,0,1,0,0]^\trans$, \qquad
$\sum_{k=1}^K x_k = 1$, \qquad
$p(\vt{x}|\vt{\mu}) = \prod_{k=1}^K \mu_k^{x_k}$, \\
$\sum_{k=1}^K \mu_k = 1$, \qquad
$\mu_k^\text{ML} = \frac{m_k}{N}$, \qquad
$m_k = \sum_{k=1}^K x_{nk}$

\subsection{Dirichlet Distribution}
$\mathrm{Dir}(\vt{\mu}|\vt{\alpha}) =
	\frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1) \cdots \Gamma(\alpha_k)}
	\prod_{k=1}^K \mu_k^{\alpha_k-1}$, \qquad
$\alpha_0 = \sum_{k=1}^K \alpha_k$

\subsection{Gaussian Distribution}
$\distNorm(x|\mu,\sigma) = \frac{1}{\sqrt{2 \pi\sigma^2}}\exp(-\frac{1}{2\sigma^2}(x-\mu)^2)$,\\
$\distNorm(\vt{x}|\vt{\mu},\vt{\Sigma}) = (2\pi)^{-\frac{D}{2}}|\vt{\Sigma}|^{-\frac{1}{2}}
	\exp\left\{-\frac{1}{2}(\vt{x}-\vt{\mu})^\trans\vt{\Sigma}^{-1}(\vt{x}-\vt{\mu})\right\}$

\subsubsection{ML for the Gaussian}
$\ln p(X|\vt{\mu},\vt{\Sigma}) = -\frac{ND}{2}\ln(2\pi) - \frac{N}{2}\ln|\vt{\Sigma}|
	-\frac{1}{2}\sum_{n=1}^N (\vt{x}_n - \vt{\mu})^\trans\vt{\Sigma}^{-1}(\vt{x}_n - \vt{\mu})$,\\
$\vt{\mu}_\text{ML} = 1/N \sum_{n=1}^N \vt{x}_n$, \qquad
$\vt{\Sigma}_\text{ML} = 1/N \sum_{n=1}^N (\vt{x}_n - \vt{\mu})^\trans (\vt{x}_n - \vt{\mu})$

\subsubsection{Stochastic gradient descent Gaussian}
$\max\ P(x_1,\cdots,x_n|\theta)$,
$\theta^N = \theta^{N-1} + \alpha_{N-1} \frac{\partial}{\partial\theta^{N-1}} \ln\ p(x_n|\theta^{N-1})$

\subsubsection{Marginal and Conditional Gaussians}
Given $p(\vt{x}) = \distNorm(\vt{x}|\vt{\mu},\vt{\Lambda}^{-1})$ and
$p(\vt{y}|\vt{x}) = \distNorm(\vt{y}|\vt{Ax}+\vt{b}, \vt{L}^{-1})$. We get \\
$p(\vt{y}) =
\distNorm(\vt{y}|\vt{A\mu}+\vt{b},\vt{L}^{-1}+\vt{A}\vt{\Lambda}^{-1}\vt{A}^\trans)$ and \\
$p(\vt{x}|\vt{y}) =
\distNorm(\vt{x}|\vt{\Sigma}[\vt{A}^\trans\vt{L}(\vt{y}-\vt{b})+\vt{\Lambda}\vt{\mu}],\vt{\Sigma})$ \\
where $\vt{\Sigma} = (\vt{\Lambda}+\vt{A}^\trans\vt{L}\vt{A})^{-1}$.

\subsection{Student's T distribution}
The heavy tail of the student-t distribution makes it more
robust against outliers.\\
$St(x|\mu,\lambda,\nu) =
\frac{\Gamma(\nu/2+1/2)}{\Gamma(\nu/2)}(\frac{\lambda^{1/2}}{(\pi
\nu)^{D/2}})
[1+\frac{\lambda(x-\mu)^2}{\nu}]^{-\nu/2-D/2}$,\\
$f_{x}(x) = \frac{\Gamma[(\nu + p)/2]}{\Gamma(\nu/2)
				\nu^{p/2} \pi^{p/2}|\Sigma|^{1/2}[1 +
				1/\nu(x-\mu)^T
\Sigma^{-1}(x-\mu)]^{(\nu+p)/2}}$\\
$\mathbb{E}(\mathbf{x}) =
\frac{\Gamma(D/2+v/2)}{\Gamma(v/2)}
\frac{|\Lambda|^{1/2}}{(\pi v)^{D/2}} \int
[1+\frac{(x-\mu)^T \Lambda
(x-\mu)}{v}]^{-D/2-v/2}x\mathrm{d}x   $


\end{multicols*}
\end{document}

